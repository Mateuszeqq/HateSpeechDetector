{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import Adam\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_metric\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device:\", device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "model_name = \"dkleczek/Polish-Hate-Speech-Detection-Herbert-Large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "hate_speech_classifier = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data processing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "                                            sentence  label\n0  Dla mnie faworytem do tytułu będzie Cracovia. ...      0\n1  @anonymized_account @anonymized_account Brawo ...      0\n2  @anonymized_account @anonymized_account Super,...      0\n3  @anonymized_account @anonymized_account Musi. ...      0\n4    Odrzut natychmiastowy, kwaśna mina, mam problem      0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Dla mnie faworytem do tytułu będzie Cracovia. ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>@anonymized_account @anonymized_account Brawo ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>@anonymized_account @anonymized_account Super,...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>@anonymized_account @anonymized_account Musi. ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Odrzut natychmiastowy, kwaśna mina, mam problem</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('hate_train.csv')\n",
    "train_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "import re\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "link_pattern = re.compile(r'^https?:\\/\\/.*[\\r\\n]*', flags=re.MULTILINE)\n",
    "\n",
    "patterns = [emoji_pattern, link_pattern]\n",
    "to_remove = ['@anonymized_account', '#', 'RT', '//', '\\\\']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "def filter_sentence(text):\n",
    "    for remove in to_remove:\n",
    "        text = text.replace(remove, \"\")\n",
    "    for pattern in patterns:\n",
    "        text = pattern.sub(r'', text)\n",
    "    text = \" \".join(text.split())\n",
    "    return text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "0        Dla mnie faworytem do tytułu będzie Cracovia. ...\n1               Brawo ty Daria kibic ma być na dobre i złe\n2        Super, polski premier składa kwiaty na grobach...\n3                              Musi. Innej drogi nie mamy.\n4          Odrzut natychmiastowy, kwaśna mina, mam problem\n                               ...                        \n10036                           Ty zagrasz? Nie wiedziałem\n10037    A VAR nie miał poprawić jakości sędziowania, t...\n10038            Szanowany, bo kolega ładnie go pożegnał ?\n10039    A kto inny ma się bić? Każdy zwyciezca ligi wo...\n10040                 A wróżbita Maciej mówi że zrozumiemy\nName: sentence, Length: 9531, dtype: object"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['sentence'] = train_df['sentence'].apply(filter_sentence)\n",
    "\n",
    "# Removing duplicates\n",
    "bool_series = train_df.duplicated(keep='first')\n",
    "train_df = train_df[~bool_series]\n",
    "train_df['sentence']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot:>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.label.value_counts().plot.bar()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "train_data, eval_data, train_targets, eval_targets = train_test_split(train_df['sentence'].values, train_df['label'].values, test_size=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def tokenize_function(in_data):\n",
    "    return tokenizer(in_data, padding=True, truncation=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "train_tokenized = tokenize_function(list(train_data))\n",
    "eval_tokenized = tokenize_function(list(eval_data))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, tokenized_data, targets):\n",
    "        self.tokenized_data = tokenized_data\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        temp = {key: torch.tensor(val[idx]) for key, val in self.tokenized_data.items()}\n",
    "        temp['label'] = torch.tensor(self.targets[idx])\n",
    "        return temp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "def get_class_weights():\n",
    "    return compute_class_weight(class_weight='balanced', classes=np.unique(train_df['label']), y=train_df['label'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.54388268 6.1970091 ]\n"
     ]
    }
   ],
   "source": [
    "print(get_class_weights())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(train_tokenized, train_targets)\n",
    "eval_dataset = MyDataset(eval_tokenized, eval_targets)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=50)\n",
    "eval_dataloader = DataLoader(eval_dataset, batch_size=40)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "def get_accuracy(model):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    metric= load_metric(\"accuracy\")\n",
    "    model.eval()\n",
    "    for batch in eval_dataloader:\n",
    "        labels = batch[\"label\"].to(device)\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        batch = {\"attention_mask\": batch['attention_mask'].to(device), \"input_ids\": batch['input_ids'].to(device)}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        y_pred.extend(predictions.cpu().numpy())\n",
    "        metric.add_batch(predictions=predictions, references=labels)\n",
    "\n",
    "    return metric.compute()['accuracy'], y_true, y_pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "# We just want to train classifier\n",
    "for param in hate_speech_classifier.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in hate_speech_classifier.classifier.parameters():\n",
    "    param.requires_grad = True"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "def train_model(model, loss_fun, optimizer):\n",
    "    num_epochs = 20\n",
    "\n",
    "    model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        losses = []\n",
    "        for batch in train_dataloader:\n",
    "\n",
    "            labels = batch[\"label\"].to(device)\n",
    "            batch = {\"attention_mask\": batch['attention_mask'].to(device), \"input_ids\": batch['input_ids'].to(device)}\n",
    "            outputs = model(**batch)\n",
    "            loss = loss_fun(outputs.logits, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            losses.append(loss.item())\n",
    "        print(f'EPOCH {epoch+1}/{num_epochs} | Loss: {np.mean(losses)}; Accuracy: {get_accuracy(model)[0]:.3f}%')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1942225095931611; Accuracy: 0.921%\n",
      "Loss: 0.18756346355855855; Accuracy: 0.922%\n",
      "Loss: 0.18412613428009103; Accuracy: 0.919%\n",
      "Loss: 0.18205233497752082; Accuracy: 0.927%\n",
      "Loss: 0.18120665595032812; Accuracy: 0.922%\n",
      "Loss: 0.17893652165052937; Accuracy: 0.926%\n",
      "Loss: 0.17839764621035725; Accuracy: 0.919%\n",
      "Loss: 0.17797874805389666; Accuracy: 0.919%\n",
      "Loss: 0.17564468626298158; Accuracy: 0.927%\n",
      "Loss: 0.1750432652439557; Accuracy: 0.926%\n",
      "Loss: 0.1766344108466619; Accuracy: 0.926%\n",
      "Loss: 0.17505770459089404; Accuracy: 0.921%\n",
      "Loss: 0.17414814288563588; Accuracy: 0.926%\n",
      "Loss: 0.17302799146938946; Accuracy: 0.922%\n",
      "Loss: 0.17272340662144367; Accuracy: 0.927%\n",
      "Loss: 0.17209555853913033; Accuracy: 0.924%\n",
      "Loss: 0.1715058814125513; Accuracy: 0.927%\n",
      "Loss: 0.17163487706406444; Accuracy: 0.922%\n",
      "Loss: 0.17183729716473156; Accuracy: 0.917%\n",
      "Loss: 0.17095364128647286; Accuracy: 0.916%\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(hate_speech_classifier.parameters(), lr=3e-4)\n",
    "loss_fun = nn.CrossEntropyLoss()\n",
    "train_model(model=hate_speech_classifier, loss_fun=loss_fun, optimizer=optimizer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 0.916%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     no_hate       0.96      0.95      0.95      1757\n",
      "        hate       0.47      0.48      0.47       150\n",
      "\n",
      "    accuracy                           0.92      1907\n",
      "   macro avg       0.71      0.72      0.71      1907\n",
      "weighted avg       0.92      0.92      0.92      1907\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['no_hate', 'hate']\n",
    "acc, y_true, y_pred = get_accuracy(hate_speech_classifier)\n",
    "print(f'Model accuracy: {acc:.3f}%')\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "torch.save(hate_speech_classifier.state_dict(), 'hate_classifier.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model training with weighting of classes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.4394223175309842; Accuracy: 0.859%\n",
      "Loss: 0.4381807320842556; Accuracy: 0.859%\n",
      "Loss: 0.43382783360730587; Accuracy: 0.859%\n",
      "Loss: 0.4289470615437607; Accuracy: 0.859%\n",
      "Loss: 0.4356796189266093; Accuracy: 0.859%\n",
      "Loss: 0.43887415820477055; Accuracy: 0.859%\n",
      "Loss: 0.43634427109964535; Accuracy: 0.859%\n",
      "Loss: 0.43893883674362905; Accuracy: 0.859%\n",
      "Loss: 0.43475082750413935; Accuracy: 0.859%\n",
      "Loss: 0.4345809753034629; Accuracy: 0.859%\n",
      "Loss: 0.43506951766466; Accuracy: 0.859%\n",
      "Loss: 0.4333746119651919; Accuracy: 0.859%\n",
      "Loss: 0.44753553645283567; Accuracy: 0.859%\n",
      "Loss: 0.4424666325543441; Accuracy: 0.859%\n",
      "Loss: 0.4374623817750831; Accuracy: 0.859%\n",
      "Loss: 0.44237711402325847; Accuracy: 0.859%\n",
      "Loss: 0.43310075219160593; Accuracy: 0.859%\n",
      "Loss: 0.4327468056889141; Accuracy: 0.859%\n",
      "Loss: 0.444519359107111; Accuracy: 0.859%\n",
      "Loss: 0.441435529905207; Accuracy: 0.859%\n"
     ]
    }
   ],
   "source": [
    "class_weights = torch.Tensor(get_class_weights()).to(device)\n",
    "loss_fun = nn.CrossEntropyLoss(weight=class_weights)\n",
    "hate_speech_classifier_weighed = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "for param in hate_speech_classifier_weighed.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in hate_speech_classifier_weighed.classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "del hate_speech_classifier\n",
    "train_model(model=hate_speech_classifier_weighed, loss_fun=loss_fun, optimizer=optimizer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 0.859%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     no_hate       0.97      0.88      0.92      1757\n",
      "        hate       0.31      0.67      0.43       150\n",
      "\n",
      "    accuracy                           0.86      1907\n",
      "   macro avg       0.64      0.77      0.67      1907\n",
      "weighted avg       0.92      0.86      0.88      1907\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc, y_true, y_pred = get_accuracy(hate_speech_classifier_weighed)\n",
    "print(f'Model accuracy: {acc:.3f}%')\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "torch.save(hate_speech_classifier_weighed.state_dict(), 'hate_classifier_weighed.pt')\n",
    "del hate_speech_classifier_weighed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hate_speech_classifier = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "hate_speech_classifier_weighed = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "hate_speech_classifier.load_state_dict(torch.load('hate_classifier.pt'))\n",
    "hate_speech_classifier_weighed.load_state_dict(torch.load('hate_classifier_weighed.pt'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without class weights: [ 2.1572924 -2.315198 ]. Prediction: 0\n",
      "With class weights: [ 1.4175406 -1.5756836]. Prediction: 0\n"
     ]
    }
   ],
   "source": [
    "text = 'Kocham cię'\n",
    "\n",
    "tokenized_text = tokenize_function(text)\n",
    "inputs_ids = tokenized_text['input_ids']\n",
    "attention_mask = tokenized_text['attention_mask']\n",
    "\n",
    "batch = {'attention_mask': torch.tensor([attention_mask]), \"input_ids\": torch.tensor([inputs_ids])}\n",
    "with torch.no_grad():\n",
    "    result = hate_speech_classifier(**batch).logits\n",
    "    prediction = torch.argmax(result, dim=-1)\n",
    "print(f'Without class weights: {result[0].cpu().numpy()}. Prediction: {prediction.item()}')\n",
    "with torch.no_grad():\n",
    "    result = hate_speech_classifier_weighed(**batch).logits\n",
    "    prediction = torch.argmax(result, dim=-1)\n",
    "print(f'With class weights: {result[0].cpu().numpy()}. Prediction: {prediction.item()}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}